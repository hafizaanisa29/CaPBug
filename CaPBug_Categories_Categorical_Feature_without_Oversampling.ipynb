{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bug ID Product Component          Assignee    Status Classification  \\\n",
      "0  528905     JDT      Core    jdt-core-inbox  RESOLVED        Eclipse   \n",
      "1  530231     JDT      Core    jdt-core-inbox  RESOLVED        Eclipse   \n",
      "2  530758     JDT      Core          jarthana  VERIFIED        Eclipse   \n",
      "3  531990     JDT      Core    jdt-core-inbox  VERIFIED        Eclipse   \n",
      "4  532137     JDT      Core  register.eclipse  VERIFIED        Eclipse   \n",
      "\n",
      "  Priority            Opened  \\\n",
      "0       P1  12/18/2017 11:46   \n",
      "1       P1    1/24/2018 5:16   \n",
      "2       P1    2/5/2018 20:38   \n",
      "3       P1     3/5/2018 0:49   \n",
      "4       P1    3/7/2018 16:17   \n",
      "\n",
      "                                             Summary       Category  \n",
      "0  JDT UI Gerrit failing with \"invalid location f...  Configuration  \n",
      "1  Compilation failure in M20180123-0400 in jdt.c...  Configuration  \n",
      "2                    Build failure in I20180205-2000  Configuration  \n",
      "3                    Build failure in I20180304-2000  Configuration  \n",
      "4  Todays update produces compile error but javac...  Configuration  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Bug Reports Dataset.csv')\n",
    "print (df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program_Anomaly      498\n",
      "GUI                  465\n",
      "Test_Code            336\n",
      "Performance          316\n",
      "Configuration        281\n",
      "NetworkOrSecurity    242\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = df['Category']\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Configuration\n",
      "1    Configuration\n",
      "2    Configuration\n",
      "3    Configuration\n",
      "4    Configuration\n",
      "5    Configuration\n",
      "6    Configuration\n",
      "7    Configuration\n",
      "Name: Category, dtype: object\n",
      "[0 0 0 0 0 0 0 0]\n",
      "0    Configuration\n",
      "1    Configuration\n",
      "2    Configuration\n",
      "3    Configuration\n",
      "4    Configuration\n",
      "5    Configuration\n",
      "6    Configuration\n",
      "7    Configuration\n",
      "8    Configuration\n",
      "9    Configuration\n",
      "Name: Category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform (classes)\n",
    "print(classes[:8])\n",
    "print(Y[:8])\n",
    "priority = df['Category']\n",
    "print(priority[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = df.dtypes == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bug ID            False\n",
       "Product            True\n",
       "Component          True\n",
       "Assignee           True\n",
       "Status             True\n",
       "Classification     True\n",
       "Priority           True\n",
       "Opened             True\n",
       "Summary            True\n",
       "Category           True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feature_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product',\n",
       " 'Component',\n",
       " 'Assignee',\n",
       " 'Status',\n",
       " 'Classification',\n",
       " 'Priority',\n",
       " 'Opened',\n",
       " 'Summary',\n",
       " 'Category']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Product', 'Component', 'Assignee', 'Status', 'Classification', 'Priority', 'Opened', 'Summary']\n"
     ]
    }
   ],
   "source": [
    "pri_col = []\n",
    "for i in categorical_cols:\n",
    "    if i != 'Category':\n",
    "        pri_col.append(i)\n",
    "print(pri_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Opened</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>717</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>273</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>948</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1367</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>272</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>98</td>\n",
       "      <td>227</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>116</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1610</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product  Component  Assignee  Status  Classification  Priority  Opened  \\\n",
       "0       44         41       144       4               4         0     475   \n",
       "1       44         41       144       4               4         0      82   \n",
       "2       44         41       141       6               4         0     717   \n",
       "3       44         41       144       6               4         0     931   \n",
       "4       44         41       273       6               4         0     948   \n",
       "5       44         41       141       6               4         0    1367   \n",
       "6       22         41         7       1               8         0     105   \n",
       "7       14        272       227       2               9         0    1407   \n",
       "8       14         98       227       5               9         0     149   \n",
       "9       14        116       227       2               9         0    1610   \n",
       "\n",
       "   Summary  \n",
       "0      691  \n",
       "1      199  \n",
       "2      133  \n",
       "3      134  \n",
       "4     1179  \n",
       "5      132  \n",
       "6      159  \n",
       "7      264  \n",
       "8     1871  \n",
       "9      343  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df[pri_col] = df[pri_col].apply(lambda col: le.fit_transform(col))\n",
    "df[pri_col].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    498\n",
       "1    465\n",
       "5    336\n",
       "3    316\n",
       "0    281\n",
       "2    242\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_minority0 = df[df.Priority==0]\n",
    "df_minority1 = df[df.Priority==1]\n",
    "df_minority2 = df[df.Priority==2]\n",
    "df_minority3 = df[df.Priority==3]\n",
    "df_minority4 = df[df.Priority==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled0 = resample(df_minority0, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=400)    # to match majority class\n",
    "df_minority_upsampled1 = resample(df_minority1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=200)    # to match majority class\n",
    "df_minority_upsampled2 = resample(df_minority2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=100)    # to match majority class\n",
    "df_minority_upsampled3 = resample(df_minority3, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=300)    # to match majority class\n",
    "df_minority_upsampled4 = resample(df_minority4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_minority_upsampled0, df_minority_upsampled1, df_minority_upsampled2, df_minority_upsampled3, df_minority_upsampled4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1025\n",
       "1     739\n",
       "0     694\n",
       "3     455\n",
       "4     425\n",
       "Name: Priority, dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Priority.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df[['Product','Classification','Component', 'Priority', 'Assignee','Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2138, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    498\n",
      "1    465\n",
      "5    336\n",
      "3    316\n",
      "0    281\n",
      "2    242\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  2  4 11 12  6]\n",
      " [ 6 53  2 12  5  6]\n",
      " [ 6  1 29  7  6  4]\n",
      " [ 5  9  5 42 11  4]\n",
      " [ 5  8  3  4 71  8]\n",
      " [ 5 10  5  4 19 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.35      0.38        54\n",
      "           1       0.64      0.63      0.63        84\n",
      "           2       0.60      0.55      0.57        53\n",
      "           3       0.53      0.55      0.54        76\n",
      "           4       0.57      0.72      0.64        99\n",
      "           5       0.40      0.31      0.35        62\n",
      "\n",
      "    accuracy                           0.54       428\n",
      "   macro avg       0.53      0.52      0.52       428\n",
      "weighted avg       0.54      0.54      0.54       428\n",
      "\n",
      "0.544392523364486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8 13  7  0 26  0]\n",
      " [ 2 41 15  3 22  1]\n",
      " [ 5  4 24  5 13  2]\n",
      " [ 6 16 13 16 24  1]\n",
      " [ 6 21  5  0 61  6]\n",
      " [ 1 17  4  0 30 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.15      0.20        54\n",
      "           1       0.37      0.49      0.42        84\n",
      "           2       0.35      0.45      0.40        53\n",
      "           3       0.67      0.21      0.32        76\n",
      "           4       0.35      0.62      0.44        99\n",
      "           5       0.50      0.16      0.24        62\n",
      "\n",
      "    accuracy                           0.37       428\n",
      "   macro avg       0.42      0.35      0.34       428\n",
      "weighted avg       0.42      0.37      0.35       428\n",
      "\n",
      "0.37383177570093457\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "#fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12  6  3 28  0]\n",
      " [ 1 49  7  6 20  1]\n",
      " [ 3  8 15  7 17  3]\n",
      " [ 4 21  5 14 31  1]\n",
      " [ 1 27  1  6 63  1]\n",
      " [ 1 18  2  3 35  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.09      0.14        54\n",
      "           1       0.36      0.58      0.45        84\n",
      "           2       0.42      0.28      0.34        53\n",
      "           3       0.36      0.18      0.24        76\n",
      "           4       0.32      0.64      0.43        99\n",
      "           5       0.33      0.05      0.08        62\n",
      "\n",
      "    accuracy                           0.35       428\n",
      "   macro avg       0.36      0.30      0.28       428\n",
      "weighted avg       0.35      0.35      0.30       428\n",
      "\n",
      "0.34813084112149534\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_test))  \n",
    "print(classification_report(y_test,y_pred_test))  \n",
    "print(accuracy_score(y_test, y_pred_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5373831775700935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(criterion = 'entropy').fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  2  7 10  6  4]\n",
      " [ 9 52  3 12  4  4]\n",
      " [ 5  3 31  4  7  3]\n",
      " [ 9 12  4 42  5  4]\n",
      " [11 12  3  7 60  6]\n",
      " [ 7  9  5  6 15 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.46      0.42        54\n",
      "           1       0.58      0.62      0.60        84\n",
      "           2       0.58      0.58      0.58        53\n",
      "           3       0.52      0.55      0.54        76\n",
      "           4       0.62      0.61      0.61        99\n",
      "           5       0.49      0.32      0.39        62\n",
      "\n",
      "    accuracy                           0.54       428\n",
      "   macro avg       0.53      0.52      0.52       428\n",
      "weighted avg       0.54      0.54      0.54       428\n",
      "\n",
      "0.5373831775700935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,dtree_predictions))  \n",
    "print(classification_report(y_test,dtree_predictions))  \n",
    "print(accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
