{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bug ID Product Component          Assignee    Status Classification  \\\n",
      "0  528905     JDT      Core    jdt-core-inbox  RESOLVED        Eclipse   \n",
      "1  530231     JDT      Core    jdt-core-inbox  RESOLVED        Eclipse   \n",
      "2  530758     JDT      Core          jarthana  VERIFIED        Eclipse   \n",
      "3  531990     JDT      Core    jdt-core-inbox  VERIFIED        Eclipse   \n",
      "4  532137     JDT      Core  register.eclipse  VERIFIED        Eclipse   \n",
      "\n",
      "  Priority            Opened  \\\n",
      "0       P1  12/18/2017 11:46   \n",
      "1       P1    1/24/2018 5:16   \n",
      "2       P1    2/5/2018 20:38   \n",
      "3       P1     3/5/2018 0:49   \n",
      "4       P1    3/7/2018 16:17   \n",
      "\n",
      "                                             Summary       Category  \n",
      "0  JDT UI Gerrit failing with \"invalid location f...  Configuration  \n",
      "1  Compilation failure in M20180123-0400 in jdt.c...  Configuration  \n",
      "2                    Build failure in I20180205-2000  Configuration  \n",
      "3                    Build failure in I20180304-2000  Configuration  \n",
      "4  Todays update produces compile error but javac...  Configuration  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Bug Reports Dataset.csv')\n",
    "print (df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3    925\n",
      "P2    539\n",
      "P1    294\n",
      "P5    225\n",
      "P4    155\n",
      "Name: Priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = df['Priority']\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    P1\n",
      "1    P1\n",
      "2    P1\n",
      "3    P1\n",
      "4    P1\n",
      "5    P1\n",
      "6    P1\n",
      "7    P1\n",
      "Name: Priority, dtype: object\n",
      "[0 0 0 0 0 0 0 0]\n",
      "0    P1\n",
      "1    P1\n",
      "2    P1\n",
      "3    P1\n",
      "4    P1\n",
      "5    P1\n",
      "6    P1\n",
      "7    P1\n",
      "8    P1\n",
      "9    P1\n",
      "Name: Priority, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform (classes)\n",
    "print(classes[:8])\n",
    "print(Y[:8])\n",
    "priority = df['Priority']\n",
    "print(priority[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = df.dtypes == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bug ID            False\n",
       "Product            True\n",
       "Component          True\n",
       "Assignee           True\n",
       "Status             True\n",
       "Classification     True\n",
       "Priority           True\n",
       "Opened             True\n",
       "Summary            True\n",
       "Category           True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feature_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product',\n",
       " 'Component',\n",
       " 'Assignee',\n",
       " 'Status',\n",
       " 'Classification',\n",
       " 'Priority',\n",
       " 'Opened',\n",
       " 'Summary',\n",
       " 'Category']"
      ]
     },
     "execution_count": 3113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Product', 'Component', 'Assignee', 'Status', 'Classification', 'Priority', 'Opened', 'Category']\n"
     ]
    }
   ],
   "source": [
    "pri_col = []\n",
    "for i in categorical_cols:\n",
    "    if i != 'Summary':\n",
    "        pri_col.append(i)\n",
    "print(pri_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Opened</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>273</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>272</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>98</td>\n",
       "      <td>227</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>116</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product  Component  Assignee  Status  Classification  Priority  Opened  \\\n",
       "0       44         41       144       4               4         0     475   \n",
       "1       44         41       144       4               4         0      82   \n",
       "2       44         41       141       6               4         0     717   \n",
       "3       44         41       144       6               4         0     931   \n",
       "4       44         41       273       6               4         0     948   \n",
       "5       44         41       141       6               4         0    1367   \n",
       "6       22         41         7       1               8         0     105   \n",
       "7       14        272       227       2               9         0    1407   \n",
       "8       14         98       227       5               9         0     149   \n",
       "9       14        116       227       2               9         0    1610   \n",
       "\n",
       "   Category  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  "
      ]
     },
     "execution_count": 3115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df[pri_col] = df[pri_col].apply(lambda col: le.fit_transform(col))\n",
    "df[pri_col].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    925\n",
       "1    539\n",
       "0    294\n",
       "4    225\n",
       "3    155\n",
       "Name: Priority, dtype: int64"
      ]
     },
     "execution_count": 3116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Priority.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_minority0 = df[df.Priority==0]\n",
    "df_minority1 = df[df.Priority==1]\n",
    "df_minority2 = df[df.Priority==2]\n",
    "df_minority3 = df[df.Priority==3]\n",
    "df_minority4 = df[df.Priority==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled0 = resample(df_minority0, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=600)    # to match majority class\n",
    "df_minority_upsampled1 = resample(df_minority1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=400)    # to match majority class\n",
    "df_minority_upsampled2 = resample(df_minority2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=250)    # to match majority class\n",
    "df_minority_upsampled3 = resample(df_minority3, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=550)    # to match majority class\n",
    "df_minority_upsampled4 = resample(df_minority4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_minority_upsampled0, df_minority_upsampled1, df_minority_upsampled2, df_minority_upsampled3, df_minority_upsampled4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1175\n",
       "1     939\n",
       "0     894\n",
       "3     705\n",
       "4     625\n",
       "Name: Priority, dtype: int64"
      ]
     },
     "execution_count": 3120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Priority.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df[['Product','Classification','Component', 'Category', 'Assignee','Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4338, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Priority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    1175\n",
      "1     939\n",
      "0     894\n",
      "3     705\n",
      "4     625\n",
      "Name: Priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 3126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[185   4   6   3   0]\n",
      " [ 10 172   8   2   1]\n",
      " [ 10  19 182   9   6]\n",
      " [  1   1   0 127  10]\n",
      " [  4   0   0   6 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       198\n",
      "           1       0.88      0.89      0.88       193\n",
      "           2       0.93      0.81      0.86       226\n",
      "           3       0.86      0.91      0.89       139\n",
      "           4       0.86      0.91      0.88       112\n",
      "\n",
      "    accuracy                           0.88       868\n",
      "   macro avg       0.88      0.89      0.88       868\n",
      "weighted avg       0.89      0.88      0.88       868\n",
      "\n",
      "0.8847926267281107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50  75  27  19  27]\n",
      " [ 24 136  16   1  16]\n",
      " [ 22  24 100  47  33]\n",
      " [ 33  15  33  44  14]\n",
      " [ 29  12  11  14  46]]\n",
      "0.43317972350230416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.25      0.28       198\n",
      "           1       0.52      0.70      0.60       193\n",
      "           2       0.53      0.44      0.48       226\n",
      "           3       0.35      0.32      0.33       139\n",
      "           4       0.34      0.41      0.37       112\n",
      "\n",
      "    accuracy                           0.43       868\n",
      "   macro avg       0.41      0.43      0.41       868\n",
      "weighted avg       0.43      0.43      0.42       868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "#fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65  67  47   7  12]\n",
      " [ 36 126  22   1   8]\n",
      " [ 31  45 107  19  24]\n",
      " [ 28  15  62  24  10]\n",
      " [ 27  10  33   6  36]]\n",
      "0.41244239631336405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.33      0.34       198\n",
      "           1       0.48      0.65      0.55       193\n",
      "           2       0.39      0.47      0.43       226\n",
      "           3       0.42      0.17      0.24       139\n",
      "           4       0.40      0.32      0.36       112\n",
      "\n",
      "    accuracy                           0.41       868\n",
      "   macro avg       0.41      0.39      0.38       868\n",
      "weighted avg       0.41      0.41      0.40       868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred_test))  \n",
    "print(metrics.accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8732718894009217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(criterion = 'entropy').fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[186   3   5   3   1]\n",
      " [ 11 168  11   2   1]\n",
      " [ 10  20 170  16  10]\n",
      " [  1   1   0 132   5]\n",
      " [  4   0   0   6 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       198\n",
      "           1       0.88      0.87      0.87       193\n",
      "           2       0.91      0.75      0.83       226\n",
      "           3       0.83      0.95      0.89       139\n",
      "           4       0.86      0.91      0.88       112\n",
      "\n",
      "    accuracy                           0.87       868\n",
      "   macro avg       0.87      0.88      0.87       868\n",
      "weighted avg       0.88      0.87      0.87       868\n",
      "\n",
      "0.8732718894009217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,dtree_predictions))  \n",
    "print(classification_report(y_test,dtree_predictions))  \n",
    "print(accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
