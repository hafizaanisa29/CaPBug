{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bug ID Product Component          Assignee    Status Classification  \\\n",
      "0  528905     JDT      Core    jdt-core-inbox  RESOLVED        Eclipse   \n",
      "1  530231     JDT      Core    jdt-core-inbox  RESOLVED        Eclipse   \n",
      "2  530758     JDT      Core          jarthana  VERIFIED        Eclipse   \n",
      "3  531990     JDT      Core    jdt-core-inbox  VERIFIED        Eclipse   \n",
      "4  532137     JDT      Core  register.eclipse  VERIFIED        Eclipse   \n",
      "\n",
      "  Priority            Opened  \\\n",
      "0       P1  12/18/2017 11:46   \n",
      "1       P1    1/24/2018 5:16   \n",
      "2       P1    2/5/2018 20:38   \n",
      "3       P1     3/5/2018 0:49   \n",
      "4       P1    3/7/2018 16:17   \n",
      "\n",
      "                                             Summary       Category  \n",
      "0  JDT UI Gerrit failing with \"invalid location f...  Configuration  \n",
      "1  Compilation failure in M20180123-0400 in jdt.c...  Configuration  \n",
      "2                    Build failure in I20180205-2000  Configuration  \n",
      "3                    Build failure in I20180304-2000  Configuration  \n",
      "4  Todays update produces compile error but javac...  Configuration  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Bug Reports Dataset.csv')\n",
    "print (df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3    925\n",
      "P2    539\n",
      "P1    294\n",
      "P5    225\n",
      "P4    155\n",
      "Name: Priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = df['Priority']\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_minority1 = df[df.Priority=='P1']\n",
    "df_minority2 = df[df.Priority=='P2']\n",
    "df_minority3 = df[df.Priority=='P3']\n",
    "df_minority4 = df[df.Priority=='P4']\n",
    "df_minority5 = df[df.Priority=='P5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled1 = resample(df_minority1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=600)    # to match majority class\n",
    "df_minority_upsampled2 = resample(df_minority2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=400)    # to match majority class\n",
    "df_minority_upsampled3 = resample(df_minority3, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=250)    # to match majority class\n",
    "df_minority_upsampled4 = resample(df_minority4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=550)    # to match majority class\n",
    "df_minority_upsampled5 = resample(df_minority5, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_minority_upsampled1, df_minority_upsampled2, df_minority_upsampled3, df_minority_upsampled4, df_minority_upsampled5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    P1\n",
      "1    P1\n",
      "2    P1\n",
      "3    P1\n",
      "4    P1\n",
      "5    P1\n",
      "6    P1\n",
      "7    P1\n",
      "Name: Priority, dtype: object\n",
      "[0 0 0 0 0 0 0 0]\n",
      "0    JDT UI Gerrit failing with \"invalid location f...\n",
      "1    Compilation failure in M20180123-0400 in jdt.c...\n",
      "2                      Build failure in I20180205-2000\n",
      "3                      Build failure in I20180304-2000\n",
      "4    Todays update produces compile error but javac...\n",
      "5    Build 4.9.0 I-Build: I20180615-0300 failed due...\n",
      "6    Cannot Start Eclipse after Plugin 'Ecore Diagr...\n",
      "7                             Crash in parseXMLElement\n",
      "8    org.mozilla.plugincontainer - EXC_BAD_ACCESS -...\n",
      "9          English language pack not updated with 61.0\n",
      "Name: Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform (classes)\n",
    "print(classes[:8])\n",
    "print(Y[:8])\n",
    "summary = df['Summary']\n",
    "print(summary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        JDT UI Gerrit failing with \"invalid location f...\n",
      "        Compilation failure in M        -     in jdt.c...\n",
      "                          Build failure in I        -    \n",
      "                          Build failure in I        -    \n",
      "        Todays update produces compile error but javac...\n",
      "                              ...                        \n",
      "        [JFace] ResourceManager throws ConcurrentModif...\n",
      "        NullPointerException in EcoreReconstructorSwit...\n",
      "        [Share] Problem sharing when project uses loca...\n",
      "        NullPointerException in org.eclipse.emf.facet....\n",
      "        NullPointerException in org.eclipse.emf.facet....\n",
      "Name: Summary, Length:     , dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "processed = re.sub(r'[\\d]', ' ',str(summary))\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       jdt ui gerrit failing with  invalid location f...\n",
      "1            compilation failure in  in jdt compiler tool\n",
      "2                                       build failure in \n",
      "3                                       build failure in \n",
      "4       todays update produces compile error but javac...\n",
      "                              ...                        \n",
      "2041      resourcemanager throws concurrentmodificatio...\n",
      "1911    nullpointerexception in ecorereconstructorswit...\n",
      "2036      problem sharing when project uses local conn...\n",
      "1992    nullpointerexception in org eclipse emf facet ...\n",
      "1994    nullpointerexception in org eclipse emf facet ...\n",
      "Name: Summary, Length: 4338, dtype: object\n"
     ]
    }
   ],
   "source": [
    "processed = summary.str.replace(r'(\\d)' , '')\n",
    "processed = processed.str.replace(r'^\\D?(\\d{3})\\D?\\D?(\\d{3})\\D?(\\d{4})$' , ' ')\n",
    "processed = processed.str.replace(r'\\s+' , ' ')\n",
    "processed = processed.str.replace(r'[ \\t]+$' , ' ')\n",
    "processed = processed.str.replace(r'[&#();*]' , ' ')\n",
    "processed = processed.str.replace(r'[,:]' , ' ')\n",
    "processed = processed.str.replace(r'[.!?\\\\-]' , ' ')\n",
    "processed = processed.str.replace(r'[//]' , ' ')\n",
    "processed = processed.str.replace(r'[|]' , ' ')\n",
    "processed = processed.str.replace(r'\\'' , ' ')\n",
    "processed = processed.str.lower()\n",
    "processed = processed.str.replace(r'\\s[a-z]\\s' , ' ')\n",
    "processed = processed.str.replace(r'\\[[^\\]]*\\]',' ')\n",
    "processed = processed.str.replace(r'\\\"',' ')\n",
    "processed = processed.str.replace(r'\\`',' ')\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Muhammad\n",
      "[nltk_data]     Wasim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = processed.apply(lambda x: ' ' .join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       jdt ui gerrit failing invalid location system ...\n",
      "1                   compilation failure jdt compiler tool\n",
      "2                                           build failure\n",
      "3                                           build failure\n",
      "4       todays update produces compile error javac com...\n",
      "                              ...                        \n",
      "2041    resourcemanager throws concurrentmodificatione...\n",
      "1911    nullpointerexception ecorereconstructorswitchb...\n",
      "2036    problem sharing project uses local connection ...\n",
      "1992    nullpointerexception org eclipse emf facet wid...\n",
      "1994    nullpointerexception org eclipse emf facet efa...\n",
      "Name: Summary, Length: 4338, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed = processed.apply(lambda x: ' ' .join(stemmer.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Muhammad\n",
      "[nltk_data]     Wasim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = processed.apply(lambda x: ' ' .join(lemmatizer.lemmatize(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jdt ui gerrit failing invalid location system ...\n",
       "1                   compilation failure jdt compiler tool\n",
       "2                                           build failure\n",
       "3                                           build failure\n",
       "4       today update produce compile error javac compi...\n",
       "                              ...                        \n",
       "2041    resourcemanager throw concurrentmodificationex...\n",
       "1911    nullpointerexception ecorereconstructorswitchb...\n",
       "2036    problem sharing project us local connection me...\n",
       "1992    nullpointerexception org eclipse emf facet wid...\n",
       "1994    nullpointerexception org eclipse emf facet efa...\n",
       "Name: Summary, Length: 4338, dtype: object"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Muhammad\n",
      "[nltk_data]     Wasim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 3720\n",
      "most common words: [('test', 800), ('eclipse', 336), ('failure', 286), ('org', 277), ('error', 260), ('build', 244), ('intermittent', 241), ('>', 238), ('memory', 208), ('java', 190), ('theme', 176), ('color', 167), ('add', 164), ('leak', 162), ('crash', 157), ('dark', 152), ('j', 148), ('ui', 146), ('tab', 146), ('update', 143), ('firefox', 139), ('plugin', 136), ('<', 136), ('exception', 134), ('type', 132), ('use', 130), ('assertion', 129), ('internal', 126), ('nullpointerexception', 126), ('code', 122), ('button', 121), ('timed', 121), ('http', 120), ('page', 119), ('method', 119), ('cpu', 118), ('jdt', 114), ('dialog', 113), ('dom', 112), ('src', 109), ('window', 108), ('content', 107), ('new', 105), ('file', 102), ('using', 102), ('null', 101), ('high', 100), ('browser', 95), ('=', 94), ('failing', 93)]\n"
     ]
    }
   ],
   "source": [
    "allwords = []\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        allwords.append(w)\n",
    "        \n",
    "allwords = nltk.FreqDist(allwords)\n",
    "\n",
    "print('Number of words: {}'.format(len(allwords)))\n",
    "print('most common words: {}'.format(allwords.most_common(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jdt ui gerrit failing invalid location system ...\n",
       "0    jdt ui gerrit failing invalid location system ...\n",
       "0    jdt ui gerrit failing invalid location system ...\n",
       "0    jdt ui gerrit failing invalid location system ...\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'eclipse', 'failure', 'org', 'error', 'build', 'intermittent', '>', 'memory', 'java', 'theme', 'color', 'add', 'leak', 'crash', 'dark', 'j', 'ui', 'tab', 'update', 'firefox', 'plugin', '<', 'exception', 'type', 'use', 'assertion', 'internal', 'nullpointerexception', 'code', 'button', 'timed', 'http', 'page', 'method', 'cpu', 'jdt', 'dialog', 'dom', 'src', 'window', 'content', 'new', 'file', 'using', 'null', 'high', 'browser', '=', 'failing']\n"
     ]
    }
   ],
   "source": [
    "word_features = allwords.most_common(50)\n",
    "word_features = [i[0] for i in word_features]\n",
    "print(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(processed).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4338, 3670)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__cfrunloopservicemachport</th>\n",
       "      <th>__format</th>\n",
       "      <th>__nscfdictionary</th>\n",
       "      <th>_cairo_array_allocate</th>\n",
       "      <th>_psutil_osx</th>\n",
       "      <th>_ssl</th>\n",
       "      <th>_tests</th>\n",
       "      <th>aa</th>\n",
       "      <th>aarch</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yubikey</th>\n",
       "      <th>zero</th>\n",
       "      <th>zerohedge</th>\n",
       "      <th>zhihu</th>\n",
       "      <th>zlib</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4338 rows Ã— 3670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      __cfrunloopservicemachport  __format  __nscfdictionary  \\\n",
       "0                            0.0       0.0               0.0   \n",
       "1                            0.0       0.0               0.0   \n",
       "2                            0.0       0.0               0.0   \n",
       "3                            0.0       0.0               0.0   \n",
       "4                            0.0       0.0               0.0   \n",
       "...                          ...       ...               ...   \n",
       "4333                         0.0       0.0               0.0   \n",
       "4334                         0.0       0.0               0.0   \n",
       "4335                         0.0       0.0               0.0   \n",
       "4336                         0.0       0.0               0.0   \n",
       "4337                         0.0       0.0               0.0   \n",
       "\n",
       "      _cairo_array_allocate  _psutil_osx  _ssl  _tests   aa  aarch   ab  ...  \\\n",
       "0                       0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "1                       0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "2                       0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "3                       0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "4                       0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "...                     ...          ...   ...     ...  ...    ...  ...  ...   \n",
       "4333                    0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "4334                    0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "4335                    0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "4336                    0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "4337                    0.0          0.0   0.0     0.0  0.0    0.0  0.0  ...   \n",
       "\n",
       "      youtube  yubikey  zero  zerohedge  zhihu  zlib  zombie  zoom  zoomed  \\\n",
       "0         0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "1         0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "2         0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "3         0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "4         0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "...       ...      ...   ...        ...    ...   ...     ...   ...     ...   \n",
       "4333      0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "4334      0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "4335      0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "4336      0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "4337      0.0      0.0   0.0        0.0    0.0   0.0     0.0   0.0     0.0   \n",
       "\n",
       "      zooming  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "...       ...  \n",
       "4333      0.0  \n",
       "4334      0.0  \n",
       "4335      0.0  \n",
       "4336      0.0  \n",
       "4337      0.0  \n",
       "\n",
       "[4338 rows x 3670 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns=vectorizer.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Priority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3    1175\n",
      "P2     939\n",
      "P1     894\n",
      "P4     705\n",
      "P5     625\n",
      "Name: Priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[185   6   6   1   0]\n",
      " [  3 158  32   0   0]\n",
      " [ 10  17 194   3   2]\n",
      " [  0   0   0 139   0]\n",
      " [  0   0   2   1 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.93      0.93      0.93       198\n",
      "          P2       0.87      0.82      0.84       193\n",
      "          P3       0.83      0.86      0.84       226\n",
      "          P4       0.97      1.00      0.98       139\n",
      "          P5       0.98      0.97      0.98       112\n",
      "\n",
      "    accuracy                           0.90       868\n",
      "   macro avg       0.92      0.92      0.92       868\n",
      "weighted avg       0.90      0.90      0.90       868\n",
      "\n",
      "0.9043778801843319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175   5   8   5   5]\n",
      " [ 15 163  10   1   4]\n",
      " [ 20  51 137  14   4]\n",
      " [  0   0   0 139   0]\n",
      " [  0   0   0   3 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.83      0.88      0.86       198\n",
      "          P2       0.74      0.84      0.79       193\n",
      "          P3       0.88      0.61      0.72       226\n",
      "          P4       0.86      1.00      0.92       139\n",
      "          P5       0.89      0.97      0.93       112\n",
      "\n",
      "    accuracy                           0.83       868\n",
      "   macro avg       0.84      0.86      0.84       868\n",
      "weighted avg       0.84      0.83      0.83       868\n",
      "\n",
      "0.8329493087557603\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "#fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[167  13  18   0   0]\n",
      " [ 10 151  26   2   4]\n",
      " [ 14  21 181   6   4]\n",
      " [  0   2   1 136   0]\n",
      " [  1   1   7   6  97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.87      0.84      0.86       198\n",
      "          P2       0.80      0.78      0.79       193\n",
      "          P3       0.78      0.80      0.79       226\n",
      "          P4       0.91      0.98      0.94       139\n",
      "          P5       0.92      0.87      0.89       112\n",
      "\n",
      "    accuracy                           0.84       868\n",
      "   macro avg       0.86      0.85      0.85       868\n",
      "weighted avg       0.84      0.84      0.84       868\n",
      "\n",
      "0.8433179723502304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred_test))  \n",
    "print(classification_report(y_test,y_pred_test))  \n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8894009216589862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(criterion = 'entropy').fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183   4  10   1   0]\n",
      " [  9 162  22   0   0]\n",
      " [ 16  20 179   5   6]\n",
      " [  0   0   0 139   0]\n",
      " [  0   0   2   1 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.88      0.92      0.90       198\n",
      "          P2       0.87      0.84      0.85       193\n",
      "          P3       0.84      0.79      0.82       226\n",
      "          P4       0.95      1.00      0.98       139\n",
      "          P5       0.95      0.97      0.96       112\n",
      "\n",
      "    accuracy                           0.89       868\n",
      "   macro avg       0.90      0.91      0.90       868\n",
      "weighted avg       0.89      0.89      0.89       868\n",
      "\n",
      "0.8894009216589862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,dtree_predictions))  \n",
    "print(classification_report(y_test,dtree_predictions))  \n",
    "print(accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
